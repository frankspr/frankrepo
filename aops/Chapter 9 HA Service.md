# 第九章 高可用架构服务

### 本章起草人：孙宇聪（coding.net CTO, 原Google SRE）

## 1. 整体框架
### 1.1 概述
运维团队是一个公司最贴近生产一线的技术部门。运维团队对高可用软件架构、高效公司研发体系有强烈的需求和最多的实践经验。运维团队是架构改造、可用性改造上最有话语权的团队。本规范将介绍运维团队针对设计和实践高可用架构中几个不同类别的成熟度模型，引用行业中的最佳实践，为读者提供通俗易懂的参考。

### 1.2 框架图

![](http://7xl5e0.com1.z0.glb.clouddn.com/C9%20001.png)

图片地址：http://7xl5e0.com1.z0.glb.clouddn.com/C9%20001.png

## 2. 最佳实践
### 2.1 研发流程优化
应用运维团队应当积极参与研发流程的每一个环节,力争在优化流程、改善沟通、推行自动化等方面为整个业务研发流程贡献力量，以达到最快最好的实现业务价值的共同目标。

#### 2.1.1 可管理级最佳实践
##### 2.1.1.1 概述
达到可管理级，应用运维团队应当积极参与业务开发计划，了解开发交付周期进度安排，能够确保运维团队有足够的人力，时间，以及工具配合完成业务需求。运维团丢需要能够及时获取资源、执行变更以帮助应用开发团队及时交付既定目标，确保新业务按时、安全上线。

##### 2.1.1.2 最佳实践
- 运维团队应该针对业务需求，做好基础架构选型工作，与开发团队共同选型业务中用到的第三方云服务提供商，第三方硬件等，确保运维团队在业务交付后有足够的人力、能力管理这些第三方服务，或者有充分准备时间学习和了解这些服务。
- 运维团队应该参与开发团队计划排期，确保运维团队有足够的时间理解新业务需求，帮助确认资源，评估变更执行难度，保障交付时运维团队有足够人力、资料执行变更。
- 了解、参与应用开发团队的产品测试流程。运维团队一方面可以增强对新业务的理解，另一方可以帮助产品团队完善测试体系，及时找到性能，可用性，可管理性等方面的缺陷，帮助产品团队提高交付质量。

#### 2.1.2 已定义级最佳实践
##### 2.1.2.1 概述
进入已定义级，应用运维团队应该与开发团队在整个开发过程中形成了有效的互相沟通体制，形成了一套有效的信息共享模式，开发团队及时将业务方面最新需求同步给运维团队，运维团队能及时为开发团队提供反馈，确保实际交付物满足运维团队操作需求。

##### 2.1.2.2 最佳实践
- 运维团队可以辅助开发团队选择一套测试框架，积极投入力量与开发团队共同开发维护一套标准的压测工具和流程，确保可能存在的性能问题在测试阶段提前显现，提前解决。
- 运维团队应该在自动化等方面大力投入，确保开发团队也能使用运维开发的自动化工具在离线测试环境中自主执行测试、部署、更新，加快迭代速度，提升交付质量。
- 运维团队可以辅助开发团队进行模拟灾难测试，找到整个业务的关键弱点，及时发现软件可用性、可靠性设计上的缺陷，将问题提前暴露，与开发部门共同商议优化。

#### 2.1.3 量化管理级最佳实践
##### 2.1.3.1 概述
进入量化管理级，应用运维团队与开发团队应该共同量化业务开发和交付过程的各项指标，针对整个流程上的弱点有的放矢的投入人力，确保业务开发过程与交付的顺畅与安全。

##### 2.1.3.2 最佳实践
- 应用运维团队应当积极推进建立一套生产环境接受性标准 (Production Acceptance Test)，为业务组件确立相关的性能基线，确保开发部门交付质量可以经过量化测试，及时暴露性能隐患、算法缺陷，架构问题等，避免上线过程中和上线之后造成事故。
- 应用运维团队应该在系统可靠性、可用性测试上投入精力。针对业务特点模拟一些可预知的灾难场景，如数据库查询变慢，流量过载，网络延迟增加等等，将问题场景提前暴露，确保开发团队有足够的数据和切实的环境来解决这些问题。

#### 2.1.4 优化管理级最佳实践
##### 2.1.4.1 概述
应用运维部门应该持续不断的参与优化整个研发流程，推行敏捷开发实践，提升迭代速度。应用运维团队应该时刻和开发团队保持同步，互相学习互相促进，共同利用更先进的技术、创新理念优化业务交付的整个过程。

应用运维部门应该确保与最终用户体验保持一致，确保业务部门所有的开发力量、运维力量都是在为业务效果最优化努力。
	
##### 2.1.4.2 最佳实践
无

===

### 2.2 生产系统管理/变更管理
运维团队最重要的职责就是管理生产环境和实施业务团队需要的变更。高效、有效的组织和管理变更，是运维团队的第一要务。

#### 2.2.1 可管理级最佳实践
##### 2.2.1.1 概述
运维团队全面接管生产系统的管理权是第一步。刚刚建立的运维团队经常处于有职无权，被动接受的情况。开发团队经常绕过团队直接操作生产环境。要达到可管理级阶段，运维团队必须要做到全程介入，并且在参与的过程中整理、总结、统一各种资源的管理、配置、建立其一套自己的资源管理规范。

##### 2.2.1.2 最佳实践
- 运维团队应该推动建立一套统一的、完备的、命名规则和管理体系。初期做到文档化，未来可以实现代码化，为最终的自动化打基础。
- 运维团队内部对程序的配置文件等形成了一套标准流程，放入VCS中管理，可以做到有记录的跟踪变更。
- 运维团队应推动业务部门建立起完整的离线测试环境、可以做到离线构建、离线验证。进一步减少在线部署的出错几率。
- 运维团队应该主动推进对变更频率的调整。 由经验得知，80% 生产环境的问题都是由新的变更引起的，而且其中80% 的问题是在部署后24小时之内就可以发现并再次需要部署。运维团队应该有计划，有目的的减少变更频率，与产品研发团队达成一致意见，共同寻找一个平衡点，给产品团队充足的时间完成本地测试、集成测试。另一方面，给运维团队留出时间优化部署流程、增加监控信号源，建立基础架构，而不是整天疲于奔命的执行变更。

#### 2.2.2 已定义级最佳实践
##### 2.2.2.1 概述
进入已定义级，运维团队的重点应该放在变更管理的规范化、标准化、自动化上。运维团队和开发团队制定了固定的发布计划、有计划的实施变更。

##### 2.2.2.2 最佳实践
- 运维团队应该有计划的建立一套变更评审流程，对生产环境的各种改变，做到有据可依，有因可查。如果能做到风险评估、回滚预案等等就更好了。
- 变更工具自动化、可重现性保障 运维团队应该着重强调提高自动化水平，将成功的流程、工具固化为标准流程、工具，确保每次变更执行可重现，可回退。做到整个流程可控。
- 运维团队应该推动变更实施的自服务化： 运维团队的特殊性经常体现在拥有生产环境权限，是唯一能够“直接”操作生产环境的团队。但是这并不代表“所有”的 生产环境操作必须由运维团队完成。一个更好的目标可以是建立起一套自服务体系，把更新能力更多的还给开发团队。 例： Nginx 服务器的配置管理很多时候是由运维团队完成的，但是某个业务内部的一些转发逻辑、细节优化等如果完全需要运维团队参与维护会带来很多不必要的等待和沟通。一个更好的方式是建立起一个自服务系统，允许开发团队自己维护配置文件。运维团队将精力投入在

 1. 对最终配置文件的自动和人工校验
 2. 对最终配置文件的自动化测试、自动化更新和回滚系统的开发。

将运维团队对Nginx服务器配置的全职参与降低为审批型参与甚至不参与，将使运维团队发挥更大的作用。
- 客户调查 作为运维团队，针对变更管理流程上也应该对服务的对象，也就是研发、产品团队做客户调查。加强自服务体系，提高流程的执行速度和可靠程度。


#### 2.2.3 量化管理级最佳实践
##### 2.2.3.1 概述
变更管理的量化管理级，通常体现在对变更执行前后对生产环境的影响是否能够量化。在变更执行初期，可以很快的判断一次变更是否会对业务造成明显的影响，从而及早发现、处理由此带来的问题。

##### 2.2.3.2 最佳实践
- 量化变更对业务的影响，关键点在于建立一套基线体系。 根据业务不同，运维团队应该着手收集、建立起一套监控体系， 收集不同信息源获得的各种信息。运维和开发共同制定一套明确的软件架构方案，架构包括对配置方式的统一、管理接口、监控接口的统一。运维团队要求新增业务组件必须重用此架构。 以 Coding 的一个后端服务器为例，在实践过程中，我们发现有主要几个信息源直接体现一个业务的健康程度:  QPS / CPU： 作为一个计算重型的业务，QPS和CPU之间的比率是很基本稳定的。Peak Memory： 该服务长期占用固定数量的内存，随着load高低变动很小。为此，在执行变更之前我们一般先确立当前版本的性能基线，具体执行变更时除了关注业务功能外，密切关注新版本的实例在这两个重要指标上是否有变化。这样如果有性能问题可以及早让开发团队介入寻找问题根源，避免变更带来大规模的业务问题。

- 变更执行自动化 Human Error是生产系统变更管理中最难排除的因素。就算有一个比较完善的变更执行文档，也会在执行过程中遇到各种各样的人为问题。只有将变更过程变成自动化的，将人放回到审核而不是执行的位置上才能本质上解决这个问题。将变更执行流程自动化的过程，也带来更好的研发、测试体验。

#### 2.2.4 优化管理级最佳实践
##### 2.2.4.1 概述
变更管理是运维部门的第一要务，是最值得花费时间、人力、物力优化的方向。运维团队应该持续不断的集思广益，收集新思路，将变更管理流程做的更好。进入优化级别，运维团队应该有能力推进工具化支持高级多维度灰度发布能力：支持A/B测试，自动化信号收集，多版本同时运行、动态切换等。

##### 2.2.4.2 最佳实践
暂无

===

### 2.3 可管理性
可管理性是运维的部门关注的另一个重点。生产环境涉及的东西越多，运维部门的压力越大。运维部门应该集中提高各类资源、业务服务的可管理性，节省人力，提高效率，降低出错几率、为未来自动化打基础。

#### 2.3.1 可管理级最佳实践
##### 2.3.1.1 概述
运维团队应该推动将所有业务服务的配置、启动、分发等方式统一化，在团队内部形成一套标准体系。这些事情有时候看起来很小，很琐碎，有时候甚至觉得不值得一做。但是聚沙成塔，如果团队成员要为每种业务记住各种各样不同的配置启动运维方式，不但增加运维团队知识共享的难度，也极大的提高了培养新成员的压力，更造成了各种各样自动化运维工具研发困难。运维团队应该在这件事情上坚持推动统一。

##### 2.3.1.2 最佳实践
- 开发或者推行一套标准的启动配置方式， 统一命令行参数、环境变量的传递等程序的配置方式。
- 推行运维系统自己维护、执行的一套完整的打包、配置、运行工具体系，力求做到跨组件、跨业务的统一。

#### 2.3.2 已定义级最佳实践
##### 2.3.2.1 概述
进入已定义级，应用运维团队应该逐步推行一套明确的软件交付规范，推进配置方式的统一、管理接口、监控接口的统一。运维团队针对管理接口基本形成了一套半自动化的脚本、或者自动化的操作工具。对组件的监控接口基本形成了一套对应的数据收集、报警等能力。

##### 2.3.2.2 最佳实践
- 推动建立一套CI系统， 自动从代码库构建推送配置文件到生产环境。
- 利用容器化等技术实现基础架构的服务化和统一化
- 利用Prometheus 等集中化的监控平台搭建一个模板化的监控环境

#### 2.3.3 量化管理级最佳实践
##### 2.3.3.1 概述
进入量化管理级，应用运维团队应该逐步推行一套明确的软件交付规范，推进配置方式的统一、管理接口、监控接口的统一。运维团队针对管理接口基本形成了一套半自动化的脚本、或者自动化的操作工具。对组件的监控接口基本形成了一套对应的数据收集、报警等能力。

##### 2.3.3.2 最佳实践
- 公司统一维护一套基础服务库或者框架。比如Coding内部推行的标准运行库，要求公司内部全部微服务使用同一套框架，同一套启动配置方式。
- 采用APM框架等自动提供一套标准化的Instrumentation 体系，自动收集汇报服务关键指标，例如CPU, Memory, Latency 等， - - - 统一收集统一监控，自动接入统一的Dashboard。
- 统一监控的覆盖率、推进组件同质化。
- 构建适合自己的集群管理平台， 如：
  - 基于 Kubernetes, Mesos, Docker 的技术的Coding 自研容器化编排系统 （参见附录）
  - 腾讯公司的织云平台级运维服务.
  - 开源的Saltstack, Chef, Pupeet 等运维管理平台.
  - 基于CloudFoundry,等构建的企业内部PaaS平台。
 
#### 2.3.4 优化管理级最佳实践
##### 2.3.4.1 概述
进入优化级，通常公司研发团队有了很长时间的共同积累，运维团队应该承担起基础库的维护工作，最大化在基础设施上的投入，不断优化底层代码和基础库的性能和效率，这将带来整个公司的研发效率和生产效率的提升。

##### 2.3.4.1最佳实践
无

===

### 2.4 流量管理、容量伸缩能力
互联网业务普遍存在着爆发性高、业务热点复杂等特点。业务运维团队想提升业务可用性的一个重要能力就是建立起一套有效的流量管理、容量伸缩能力，能够将现有的有限资源动态分配，合理利用达到最好的业务效果。

#### 2.4.1 可管理级最佳实践
##### 2.4.1.1 概述
进入可管理级，应用运维团队应该建立了基本的流量管理能力。能够针对可预见的流量变化配备合适的资源，有相应的预警措施，有处理过载的能力。

##### 2.4.1.2 最佳实践
- 运维团队通过常见开源软件、第三方负载均衡器等实现手动的、基本入口级整体流量管理控制，可以按常见变量如IP、域名、API接口等维度进行简单的流量管控.
- 运维团队可以通过部署IDS 或流量分析系统为整个业务提供可见性支持，收集业务中各种优先级的流量的重要性和健康度指标。
- 运维团队可以根据业务需要和资源配置情况对业务中不重要的流量进行有损的手工调控, 

>例如：双11等电商秒杀关键时刻资源紧张时可以丢弃一些不重要的流量，保障关键性业务的正常运转。

#### 2.4.2 已定义级最佳实践
##### 2.4.2.1 概述
进入已定义级，要求运维团队有全局流量管控的能力。能够根据业务的不同需要，结合实际物理资源情况等迅速进行流量调整、容量再配置。

##### 2.4.2.2 最佳实践
- 运维团队可以针对业务中不同的优先级流量指定相应的服务水平指标，通过L2, L3, L7 不同层面的调节措施限速、排队等等达到限速目标。
- 运维团队可以提供更高级，精确的流量控制工具可以按照业务特点精确的进行流量调整。
- 运维团队可以建立对后端服务的自动化保护机制防止过载和连锁故障的发生。

#### 2.4.3 量化管理级最佳实践
##### 2.4.3.1 概述
量化管理级要求运维团队运维团队支持流量管控配置与服务发现等自动化工具结合，支持动态调整、自动更新等。

##### 2.4.3.2 最佳实践
- 例如：利用容器化等技术，根据实时流量自动扩展、收缩后端系统。
- 又例: Youtube转码系统可以根据目前实时视频上传转码的需要自动配置不同格式的转码器的部署数量，达到最优化的资源配置机制。
- 负载均衡器在进行流量的分配时，同时收集后端的健康度信号，自动评判哪些流量造成了系统性热点，自动分摊，自动聚合类似流量起到合理利用资源的目的。
- 运维团队可以推行后端组件自行监控资源占用情况，包括CPU,Memory等如果发现系统资源占用情况到达一定阈值，停止接收新请求，避免系统过载、资源不够导致的性能急剧下降或者崩溃。
- 流量管控系统可以进行自动Query-of-death检测，如果发现某一类请求会造成后端的不可用， 可以及时的做到自动屏蔽、发送报警，进一步缩短针对未知问题的防御程度，进一步提高整个系统的鲁棒性、可靠性。

#### 2.4.4 优化管理级最佳实践
##### 2.4.4.1 概述
进入优化级，运维团队应该将重点放在合理利用资源，保护系统热点，提高系统可用性的关键性能力。在复杂业务系统中，每个系统组件都可能并行处理多种不同业务。其中难免在某一类业务中出现不可预知的热点、逻辑问题导致整个系统出现问题。常见的现象包括：某一类请求资源消耗过高、某种特殊组合造成系统死锁、某中意外输入导致程序崩溃等。运维团队应该推行自动化的容量伸缩、流量管控能力用以提高系统的鲁棒性，可用性，将紧急问题降级为资源问题。

##### 2.4.4.2 最佳实践
暂无

===

### 2.5 灾难处理能力
应用运维团队通常是公司的救火队员，承担着关键时刻保障业务可持续性的压力。所以灾难处理能力是运维团队平时应该最重视培养的一项能力。

#### 2.5.1 可管理级最佳实践
##### 2.5.1.1 概述
灾难处理能力可管理级，要求运维团队在关键时刻必须能够充当合格的救火队。在紧急时刻，能够及时响应问题，能够可靠、准确的定位问题，能够及时、有效的集合公司内外的人力、物理等力量共同解决业务部门遇到的问题。要做到这些，就要在非关键时刻下工夫。运维团队平时必须有计划的将保障业务系统正常运行的涉及到的各种硬件、软件、第三方系统、基础设施等等各个方面的关键信息、联系人、紧急处理流程等完全掌握。

##### 2.5.1.2 最佳实践
- 建立一套合理的、灵活的、多级的 Oncall 体制，保障随时有人力响应紧急情况。轮值制度应该考虑的点包括：
  - 灾难升级制度：好的轮值制度应该分级处理，尽量将每次紧急情况的处理在报警前预先分类，按级报警，力求一次性找到对应的人来处理。
  - 对响应时间的要求要明确：非关键性业务的响应时间可以是小时级，关键业务的响应时间应该在分钟级。轮值人员务必在响应时间内及时上线开始处理问题。
  - 有足够的轮值力量和后备方案，确保当轮值人员有意外情况时，可以有其他的后备力量接替等。
  - 适当的补偿体系。
- 培养良好的事后复盘体制，将每次灾难处理当成一次学习机会，力求将混乱、复杂的灾难处理流程文档化、记录化。为以后的提升和内部培训积累资料。
- 定时组织灾难处理流程的演习，确保团队每个人熟悉业务灾难处理流程，掌握各种信息、工具，能够有效的在关键时刻调动各种资源解决问题。

#### 2.5.2 已定义级最佳实践
##### 2.5.2.1 概述
进入已定义级意味着运维团队对于业务运行问题不再是被动的处理过程，而是逐渐进入一种主动模式。运维团队有计划的排除潜在问题，致力于业务的关键组件的可靠性提升，有计划有目的的降低问题发生的可能性。

##### 2.5.2.2 最佳实践
- 运维团队有计划的测试、验证、优化各种硬件、软件配置保证常见单点灾难不会造成数据的丢失，损坏。确保硬件恢复之后可在1-X分钟内正常恢复服务，不会出现无法启动、无法重新部署的问题。
- 推行计划内不可用时间：运维部门应该鼓励开发部门利用计划内不可用时间上线测试新功能，将新业务、新改变带来的风险分摊。

#### 2.5.3 量化管理级最佳实践
##### 2.5.3.1 概述
进入量化管理级，要求运维团队针对业务恢复时间制定明确的SLA，将业务风险量化，定期进行灾难恢复演习，确保业务恢复的流程完备、可重现。

##### 2.5.3.2 最佳实践
- 产品软件架构升级：提升可靠性的一个关键性就是运维部门应该联合开发部门一起推动业务组件支持按主、从模式部署，热备优于冷备。力求故障切换时间可在1-X小时内完成。整套过程尽量自动化，无业务降级、无数据丢失。
- 运维团队推动服务架构升级支持分片式(sharding)部署。可以自动进行主从切换、动态重分片等，进一步减少不可用时间。

#### 2.5.4 优化管理级最佳实践
##### 2.5.4.1 概述
进入优化管理级，运维部门应该致力于与业务部门共同努力为公司业务制定切实有用的风险模型，支持在有限预算和有限容量下最优化业务运行能力的目标。很多业务本身上就存在严重的资源竞争、负载难以预估、系统热点明显等特性。这些特性问题只能通过架构改进，但是却无法根除。任何一个业务团队所能投人力和物力都是有限的，运维团队就要在这种情况下和业务团队共同探寻一套可以接受的系统降级方案。在物理资源、人力资源有限的情况下制定出系统降级方案，保障业务顺利进行，出现问题也始终处于可接受的范围内。

##### 2.5.4.2 最佳实践
暂无
